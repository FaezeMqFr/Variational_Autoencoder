{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href='https://colab.research.google.com/https://github.com/FaezeMqFr/Variational_Autoencoder/edit/main/VAE_MNIST.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import gzip\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "train_images = 'train-images-idx3-ubyte.gz'\n",
    "train_labels = 'train-labels-idx1-ubyte.gz'\n",
    "test_images = 't10k-images-idx3-ubyte.gz'\n",
    "test_labels = 't10k-labels-idx1-ubyte.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load the dataset\n",
    "def load_mnist(images_path: str, labels_path: str):\n",
    "    with gzip.open(urllib.request.urlopen(url + images_path)) as f:\n",
    "        images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28)\n",
    "    with gzip.open(urllib.request.urlopen(url + labels_path)) as f:\n",
    "        labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return images, labels\n",
    "\n",
    "# Load data\n",
    "train_images, train_labels = load_mnist(train_images, train_labels)\n",
    "test_images, test_labels = load_mnist(test_images, test_labels)\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Split train data into train and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Variational Autoencoder (VAE) model\n",
    "class VAE(models.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dense(latent_dim * 2),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dense(784, activation='sigmoid'),\n",
    "            layers.Reshape((28, 28))\n",
    "        ])\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, log_var = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, log_var\n",
    "\n",
    "    def reparameterize(self, mean, log_var):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(log_var * 0.5) + mean\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the VAE model\n",
    "latent_dim = 2\n",
    "vae = VAE(latent_dim)\n",
    "\n",
    "# Define the VAE loss function\n",
    "def vae_loss(x, recon_x, mean, log_var):\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=recon_x, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2])\n",
    "    kl_div = -0.5 * tf.reduce_sum(1 + log_var - tf.square(mean) - tf.exp(log_var), axis=1)\n",
    "    return -tf.reduce_mean(logpx_z + kl_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the VAE model\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "vae.fit(train_images, epochs=50, batch_size=64, validation_data=(val_images, val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display images from the VAE\n",
    "def plot_images(images):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(10, 10))\n",
    "    for img, ax in zip(images, axes):\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(img.reshape(28, 28), cmap='gray')\n",
    "plot_images(vae.decode(tf.random.normal(shape=(10, latent_dim))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
